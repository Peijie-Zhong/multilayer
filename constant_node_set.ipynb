{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "803345a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sync_data/test.csv complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from algorithms import *\n",
    "\n",
    "filename = \"test\"\n",
    "input_file = f'sync_data/{filename}.csv'\n",
    "output_file = f'output/{filename}_communities.csv'\n",
    "\n",
    "infomap_communities(input_file, output_file, jsd_relax_rate=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "615050e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9689558713891129, 1.0, 0.949908182959097, 0.9151600052193318]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9668048119135083"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from measurement import *\n",
    "\n",
    "compute_layerwise_ami_avg(\"test\",\"sync_data\",output_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e761f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved community assignments -> out/infomap_state_nodes.csv (1820 nodes)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ========= CONFIG =========\n",
    "CSV_PATH = \"sync_data/test.csv\"\n",
    "# node2vec\n",
    "DIMENSIONS = 32\n",
    "WALK_LENGTH = 80\n",
    "NUM_WALKS = 10\n",
    "P = 1.0\n",
    "Q = 1.0\n",
    "WINDOW = 10\n",
    "WORKERS = 4\n",
    "SEED = 42\n",
    "# GW & interlayer linking\n",
    "GW_EMB_METRIC = \"euclidean\"       # 'euclidean' or 'cosine'\n",
    "TOP_K = 5                         # 每个源节点跨层只保留前 K 个目标\n",
    "MIN_WEIGHT = 1e-3                 # 小于阈值的跨层边丢弃\n",
    "ALPHA = 2.0                       # 层间全局缩放 Omega = exp(-ALPHA * GW)\n",
    "INTRA_EDGE_WEIGHT = 1.0           # 层内边权（CSV 若无权重，就用常数 1）\n",
    "\n",
    "# ========= deps =========\n",
    "from node2vec import Node2Vec\n",
    "from ot.gromov import gromov_wasserstein, gromov_wasserstein2\n",
    "from infomap import Infomap\n",
    "\n",
    "\n",
    "# ---------- data / graphs ----------\n",
    "def read_edges(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    req = {\"u\", \"v\", \"layer\"}\n",
    "    miss = req - set(df.columns)\n",
    "    if miss:\n",
    "        raise ValueError(f\"CSV missing required columns: {sorted(miss)}\")\n",
    "    # 统一为字符串 id\n",
    "    df[\"u\"] = df[\"u\"].astype(str)\n",
    "    df[\"v\"] = df[\"v\"].astype(str)\n",
    "    df[\"layer\"] = df[\"layer\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def build_layer_graphs(df: pd.DataFrame) -> Dict[str, nx.Graph]:\n",
    "    graphs: Dict[str, nx.Graph] = {}\n",
    "    for layer, gdf in df.groupby(\"layer\"):\n",
    "        G = nx.Graph()\n",
    "        if \"w\" in gdf.columns:\n",
    "            edges = [(u, v, float(w)) for u, v, w in gdf[[\"u\", \"v\", \"w\"]].itertuples(index=False)]\n",
    "            G.add_weighted_edges_from(edges)\n",
    "        else:\n",
    "            G.add_edges_from(gdf[[\"u\", \"v\"]].itertuples(index=False, name=None))\n",
    "            # 给无权图统一权重 1\n",
    "            nx.set_edge_attributes(G, INTRA_EDGE_WEIGHT, \"weight\")\n",
    "        # 确保孤立点也在图里（如果 CSV 有只出现一次的端点）\n",
    "        for col in [\"u\", \"v\"]:\n",
    "            for n in gdf[col].unique():\n",
    "                if n not in G:\n",
    "                    G.add_node(n)\n",
    "        graphs[layer] = G\n",
    "    return graphs\n",
    "\n",
    "\n",
    "# ---------- embeddings ----------\n",
    "def compute_node2vec_embeddings(\n",
    "    G: nx.Graph,\n",
    "    dimensions=64, walk_length=80, num_walks=10, p=1.0, q=1.0,\n",
    "    window=10, workers=1, seed=42\n",
    ") -> pd.DataFrame:\n",
    "    if len(G) == 0:\n",
    "        raise ValueError(\"Empty graph.\")\n",
    "    def _fit(n_jobs):\n",
    "        n2v = Node2Vec(G, dimensions=dimensions, walk_length=walk_length,\n",
    "                       num_walks=num_walks, p=p, q=q, workers=n_jobs,\n",
    "                       seed=seed, quiet=True)\n",
    "        return n2v.fit(window=window, min_count=1, batch_words=4)\n",
    "    try:\n",
    "        model = _fit(workers)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] node2vec workers={workers} failed: {e}. Fallback to workers=1.\")\n",
    "        model = _fit(1)\n",
    "    nodes = [str(n) for n in G.nodes()]\n",
    "    X = np.vstack([model.wv[n] for n in nodes])\n",
    "    emb = pd.DataFrame(X, index=nodes, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "    emb.index.name = \"node\"\n",
    "    return emb\n",
    "\n",
    "def pairwise_from_embeddings(emb: pd.DataFrame, metric=\"euclidean\") -> np.ndarray:\n",
    "    X = emb.values.astype(float)\n",
    "    if metric == \"euclidean\":\n",
    "        s = np.sum(X * X, axis=1, keepdims=True)\n",
    "        D2 = s + s.T - 2 * (X @ X.T)\n",
    "        np.maximum(D2, 0.0, out=D2)\n",
    "        return np.sqrt(D2, dtype=float)\n",
    "    elif metric == \"cosine\":\n",
    "        n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "        n[n == 0] = 1.0\n",
    "        Xn = X / n\n",
    "        S = np.clip(Xn @ Xn.T, -1.0, 1.0)\n",
    "        return 1.0 - S\n",
    "    else:\n",
    "        raise ValueError(\"metric must be 'euclidean' or 'cosine'.\")\n",
    "\n",
    "def gw_coupling_and_distance(emb1: pd.DataFrame, emb2: pd.DataFrame, metric=\"euclidean\"):\n",
    "    emb1 = emb1.sort_index()\n",
    "    emb2 = emb2.sort_index()\n",
    "    nodes1 = emb1.index.to_list()\n",
    "    nodes2 = emb2.index.to_list()\n",
    "    C1 = pairwise_from_embeddings(emb1, metric=metric)\n",
    "    C2 = pairwise_from_embeddings(emb2, metric=metric)\n",
    "    n1, n2 = C1.shape[0], C2.shape[0]\n",
    "    p = np.ones(n1) / max(n1, 1)\n",
    "    q = np.ones(n2) / max(n2, 1)\n",
    "    # π（最优耦合，带熵正则版可用 ot.gromov.entropic_gromov_wasserstein）\n",
    "    pi = gromov_wasserstein(C1, C2, p, q, loss_fun=\"square_loss\")\n",
    "    # GW^2\n",
    "    gw2 = gromov_wasserstein2(C1, C2, p, q, loss_function=\"square_loss\")\n",
    "    gw = float(np.sqrt(max(gw2, 0.0)))\n",
    "    return pi, nodes1, nodes2, gw\n",
    "\n",
    "def state_id(node: str, layer: str) -> str:\n",
    "    # 选择一个不太可能出现在节点/层名里的分隔符\n",
    "    return f\"{node}|{layer}\"\n",
    "\n",
    "\n",
    "def build_infomap_with_gw(\n",
    "    graphs: Dict[str, nx.Graph],\n",
    "    embeddings: Dict[str, pd.DataFrame],\n",
    "    layer_order: List[str],\n",
    "    top_k: int = 5,\n",
    "    min_weight: float = 1e-3,\n",
    "    alpha: float = 2.0,\n",
    "    emb_metric: str = \"euclidean\",\n",
    "    intra_weight_from_attr: str = \"weight\"\n",
    ") -> Tuple[Infomap, Dict[int, Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    构造扁平化“状态节点图”，节点是 (node, layer) 的组合映射为 int。\n",
    "    返回 (Infomap实例, id2state)，其中 id2state[i] = (node, layer)\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------- 1️⃣ 建立全局状态节点映射 -----------\n",
    "    state2id = {}\n",
    "    id2state = {}\n",
    "    next_id = 1\n",
    "\n",
    "    # 遍历所有层的所有节点，创建唯一的整数ID\n",
    "    for layer in layer_order:\n",
    "        for n in graphs[layer].nodes():\n",
    "            key = (str(n), str(layer))\n",
    "            state2id[key] = next_id\n",
    "            id2state[next_id] = key\n",
    "            next_id += 1\n",
    "\n",
    "    im = Infomap(\"--two-level --silent\")\n",
    "\n",
    "    # ----------- 2️⃣ 层内边 -----------\n",
    "    for layer in layer_order:\n",
    "        G = graphs[layer]\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            w = float(d.get(intra_weight_from_attr, INTRA_EDGE_WEIGHT))\n",
    "            uid = state2id[(str(u), str(layer))]\n",
    "            vid = state2id[(str(v), str(layer))]\n",
    "            im.addLink(int(uid), int(vid), float(w))\n",
    "\n",
    "        # 如果整层没有边，加极小自环，保证节点可见\n",
    "        if G.number_of_edges() == 0:\n",
    "            for n in G.nodes():\n",
    "                nid = state2id[(str(n), str(layer))]\n",
    "                im.addLink(int(nid), int(nid), 1e-12)\n",
    "\n",
    "    # ----------- 3️⃣ 层间边 (GW 耦合) -----------\n",
    "    for t in range(len(layer_order) - 1):\n",
    "        la, lb = layer_order[t], layer_order[t + 1]\n",
    "        emb_a, emb_b = embeddings[la].sort_index(), embeddings[lb].sort_index()\n",
    "        pi, nodes_a, nodes_b, gw = gw_coupling_and_distance(emb_a, emb_b, metric=emb_metric)\n",
    "\n",
    "        Omega = float(np.exp(-alpha * gw))  # 全局缩放\n",
    "        row_sums = pi.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1.0\n",
    "        P = pi / row_sums\n",
    "\n",
    "        na, nb = P.shape\n",
    "        for ia in range(na):\n",
    "            k_use = min(top_k, nb) if top_k > 0 else nb\n",
    "            idx = np.argpartition(-P[ia, :], kth=k_use - 1)[:k_use]\n",
    "            idx = idx[np.argsort(-P[ia, idx])]\n",
    "\n",
    "            src_name = nodes_a[ia]\n",
    "            src_id = state2id[(str(src_name), str(la))]\n",
    "\n",
    "            for jb in idx:\n",
    "                w = float(P[ia, jb]) * Omega\n",
    "                if w < min_weight:\n",
    "                    continue\n",
    "                dst_name = nodes_b[jb]\n",
    "                dst_id = state2id[(str(dst_name), str(lb))]\n",
    "                im.addLink(int(src_id), int(dst_id), float(w))\n",
    "\n",
    "    return im, id2state\n",
    "\n",
    "\n",
    "# ============ RUN ============\n",
    "df = read_edges(CSV_PATH)\n",
    "graphs = build_layer_graphs(df)\n",
    "layer_names = sorted(graphs.keys(), key=lambda x: x)  # 你也可以自定义顺序\n",
    "\n",
    "# 逐层嵌入\n",
    "embeddings: Dict[str, pd.DataFrame] = {}\n",
    "for layer in layer_names:\n",
    "    embeddings[layer] = compute_node2vec_embeddings(\n",
    "        graphs[layer],\n",
    "        dimensions=DIMENSIONS, walk_length=WALK_LENGTH, num_walks=NUM_WALKS,\n",
    "        p=P, q=Q, window=WINDOW, workers=WORKERS, seed=SEED\n",
    "    )\n",
    "\n",
    "    \n",
    "im, id2state = build_infomap_with_gw(\n",
    "    graphs, embeddings, layer_order=layer_names,\n",
    "    top_k=TOP_K, min_weight=MIN_WEIGHT, alpha=ALPHA, emb_metric=GW_EMB_METRIC\n",
    ")\n",
    "\n",
    "im.run()\n",
    "\n",
    "# 提取社区划分结果\n",
    "partition = {n.node_id: n.module_id for n in im.tree if n.is_leaf}\n",
    "\n",
    "# 映射回 (node, layer)\n",
    "rows = []\n",
    "for nid, com in partition.items():\n",
    "    if nid in id2state:\n",
    "        node, layer = id2state[nid]\n",
    "        rows.append((node, layer, com))\n",
    "\n",
    "assignments_df = pd.DataFrame(rows, columns=[\"node_id\", \"layer\", \"community\"])\n",
    "assignments_df.to_csv(\"out/infomap_state_nodes.csv\", index=False)\n",
    "print(f\"Saved community assignments -> out/infomap_state_nodes.csv ({len(rows)} nodes)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be119077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6052790034077675, 0.9344613973053375, 0.8789571703502499, 0.9038561123671298, 0.9164749858448414]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8478057338550652"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from measurement import *\n",
    "\n",
    "compute_layerwise_ami_avg(\"test\",\"sync_data\",output_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1553eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  node_id layer  community\n",
      "0       0     0          1\n",
      "1      57     0          1\n",
      "2      70     0          2\n",
      "3      21     0          1\n",
      "4      17     0          1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "from typing import Dict, Tuple, List\n",
    "from hetero_coupling import *\n",
    "\n",
    "def layer_adjacency_matrix(G: nx.Graph, node_order: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    把单层加权无向图转成邻接矩阵 (|V|x|V|), 顺序由 node_order 决定.\n",
    "    \"\"\"\n",
    "    idx = {n: i for i, n in enumerate(node_order)}\n",
    "    N = len(node_order)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if u not in idx or v not in idx:\n",
    "            continue\n",
    "        w = data.get(\"weight\", 1.0)\n",
    "        i = idx[u]\n",
    "        j = idx[v]\n",
    "        rows.append(i); cols.append(j); vals.append(w)\n",
    "        rows.append(j); cols.append(i); vals.append(w)\n",
    "    if N == 0:\n",
    "        return np.zeros((0, 0), dtype=float)\n",
    "    A = sparse.coo_matrix((vals, (rows, cols)), shape=(N, N)).toarray()\n",
    "    np.fill_diagonal(A, 0.0)\n",
    "    return A\n",
    "\n",
    "def supra_adjacency_from_pi(\n",
    "    graphs: Dict[str, nx.Graph],\n",
    "    embeddings: Dict[str, pd.DataFrame],\n",
    "    metric: str = \"euclidean\",\n",
    "    omega_scale: float = 1.0,\n",
    ") -> Tuple[np.ndarray, List[Tuple[str, str]], Dict[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    构建超邻接矩阵 A_supra (dense)，以及映射关系。\n",
    "\n",
    "    重要区别（和上一版比）：\n",
    "    - 只在“相邻层”之间加入跨层耦合 (layer_t <-> layer_{t+1})\n",
    "      不再对所有成对层 (t, s) 都加边。\n",
    "\n",
    "    返回:\n",
    "      A_supra: (sum_l |V_l|) x (sum_l |V_l|) 的 numpy.ndarray\n",
    "      global_index: [(layer, node), ...] 对应 A_supra 的行/列顺序\n",
    "      layer_nodes: {layer: [node,...]} 每层节点顺序\n",
    "    \"\"\"\n",
    "    # 让层有一个稳定顺序（时间顺序 / 层序）\n",
    "    layers_sorted = sorted(graphs.keys())\n",
    "\n",
    "    # 1. 为每一层确定节点顺序（优先用该层 embedding 的 index）\n",
    "    layer_nodes: Dict[str, List[str]] = {}\n",
    "    for layer in layers_sorted:\n",
    "        nodes_emb = [str(n) for n in embeddings[layer].index.tolist()]\n",
    "        extra = [str(n) for n in graphs[layer].nodes() if str(n) not in nodes_emb]\n",
    "        full_nodes = nodes_emb + extra\n",
    "        # 去重保持顺序\n",
    "        seen = set()\n",
    "        ordered_nodes = []\n",
    "        for n in full_nodes:\n",
    "            if n not in seen:\n",
    "                seen.add(n)\n",
    "                ordered_nodes.append(n)\n",
    "        layer_nodes[layer] = ordered_nodes\n",
    "\n",
    "    # 2. 每层内邻接块\n",
    "    layer_adj_blocks: Dict[str, np.ndarray] = {}\n",
    "    for layer in layers_sorted:\n",
    "        layer_adj_blocks[layer] = layer_adjacency_matrix(\n",
    "            graphs[layer],\n",
    "            layer_nodes[layer]\n",
    "        )\n",
    "\n",
    "    # 3. 只计算“相邻层(t, t+1)”的跨层块\n",
    "    #    coupling_blocks[(la, lb)] = 矩阵 (|V_la| x |V_lb|)\n",
    "    coupling_blocks: Dict[Tuple[str, str], np.ndarray] = {}\n",
    "\n",
    "    for k in range(len(layers_sorted) - 1):\n",
    "        la = layers_sorted[k]\n",
    "        lb = layers_sorted[k + 1]\n",
    "\n",
    "        emb_a = embeddings[la]\n",
    "        emb_b = embeddings[lb]\n",
    "\n",
    "        # pi: shape (|V_la'| x |V_lb'|)\n",
    "        # nodes_a, nodes_b 对应 pi 的行/列索引\n",
    "        pi, nodes_a, nodes_b, gw_dist = gw_coupling_and_distance(\n",
    "            emb_a, emb_b, metric=metric\n",
    "        )\n",
    "\n",
    "        # 我们需要把 pi 的行/列顺序对齐到 layer_nodes[la], layer_nodes[lb]\n",
    "        idx_a = {n: i for i, n in enumerate(nodes_a)}\n",
    "        idx_b = {n: j for j, n in enumerate(nodes_b)}\n",
    "\n",
    "        na = len(layer_nodes[la])\n",
    "        nb = len(layer_nodes[lb])\n",
    "\n",
    "        C = np.zeros((na, nb), dtype=float)\n",
    "\n",
    "        # 把 GW 耦合强度映射到 (la节点顺序, lb节点顺序)\n",
    "        for ia, node_a in enumerate(layer_nodes[la]):\n",
    "            ka = idx_a.get(node_a, None)\n",
    "            if ka is None:\n",
    "                continue\n",
    "            row_pi = pi[ka, :]  # pi[ka, :] 对应 node_a -> 所有 node_b\n",
    "            for ib, node_b in enumerate(layer_nodes[lb]):\n",
    "                kb = idx_b.get(node_b, None)\n",
    "                if kb is None:\n",
    "                    continue\n",
    "                C[ia, ib] = row_pi[kb]\n",
    "\n",
    "        if omega_scale != 1.0:\n",
    "            C = C * float(omega_scale)\n",
    "\n",
    "        # 保存 t -> t+1 的块 和 对称的 t+1 -> t\n",
    "        coupling_blocks[(la, lb)] = C\n",
    "        coupling_blocks[(lb, la)] = C.T\n",
    "\n",
    "    # 4. 把这些块拼成一个大矩阵\n",
    "    # 4a. 给每层一个 offset，方便把子块放进总矩阵\n",
    "    layer_offset: Dict[str, int] = {}\n",
    "    offset = 0\n",
    "    for layer in layers_sorted:\n",
    "        layer_offset[layer] = offset\n",
    "        offset += len(layer_nodes[layer])\n",
    "    total_N = offset\n",
    "\n",
    "    A_supra = np.zeros((total_N, total_N), dtype=float)\n",
    "\n",
    "    # 4b. 放每层内部邻接 (对角块)\n",
    "    for layer in layers_sorted:\n",
    "        A_block = layer_adj_blocks[layer]\n",
    "        base = layer_offset[layer]\n",
    "        na = A_block.shape[0]\n",
    "        if na == 0:\n",
    "            continue\n",
    "        A_supra[base:base+na, base:base+na] = A_block\n",
    "\n",
    "    # 4c. 放相邻层之间的耦合块\n",
    "    for (la, lb), C_ab in coupling_blocks.items():\n",
    "        base_a = layer_offset[la]\n",
    "        base_b = layer_offset[lb]\n",
    "        na, nb = C_ab.shape\n",
    "        if na == 0 or nb == 0:\n",
    "            continue\n",
    "        A_supra[base_a:base_a+na, base_b:base_b+nb] = C_ab\n",
    "\n",
    "    # 5. global_index: A_supra 的行/列对应哪个 (layer,node)\n",
    "    global_index: List[Tuple[str, str]] = []\n",
    "    for layer in layers_sorted:\n",
    "        for node in layer_nodes[layer]:\n",
    "            global_index.append((layer, node))\n",
    "\n",
    "    return A_supra, global_index, layer_nodes, layer_adj_blocks, coupling_blocks\n",
    "\n",
    "def modularity_matrix(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    给定加权无向图的邻接矩阵 A，构造经典 Newman-Girvan 模块度矩阵 B:\n",
    "        B = A - (k k^T) / (2m)\n",
    "    其中 k 是度向量, 2m = sum(A_ij).\n",
    "    \"\"\"\n",
    "    # 度\n",
    "    k = A.sum(axis=1, keepdims=True)  # shape (N,1)\n",
    "    two_m = float(k.sum())            # scalar = sum of all weights\n",
    "    if two_m <= 0:\n",
    "        # 没边的情况下，B 就是 0 矩阵\n",
    "        return np.zeros_like(A, dtype=float)\n",
    "\n",
    "    expected = (k @ k.T) / two_m      # outer product / (2m)\n",
    "    B = A - expected\n",
    "    # 可选：去掉非常小的数值噪声\n",
    "    B[np.abs(B) < 1e-15] = 0.0\n",
    "    return B\n",
    "\n",
    "\n",
    "def build_B_from_blocks(\n",
    "    layer_adj_blocks: Dict[str, np.ndarray],\n",
    "    coupling_blocks: Dict[Tuple[str, str], np.ndarray],\n",
    "    layer_nodes: Dict[str, List[str]],\n",
    "    gamma: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    构造与 multiord 等价的模块度矩阵 B（block-wise）。\n",
    "\n",
    "    参数:\n",
    "    - layer_adj_blocks: {layer: A_s (n_s x n_s)} 只包含层内邻接，不包含跨层耦合\n",
    "    - coupling_blocks: {(la,lb): C_{ab} (n_a x n_b)} 仅包含要作为跨层耦合直接加入 B 的块。\n",
    "                       对 (la,lb) 和 (lb,la) 应该互为转置或同时提供。\n",
    "                       只需提供相邻层的块（或所有你希望有耦合的块）。\n",
    "    - layer_nodes: {layer: [node,...]} 决定 block 的顺序与 offset\n",
    "    - gamma: 分辨率参数（对所有层同一个 gamma；也可改成 dict per-layer）\n",
    "\n",
    "    返回:\n",
    "    - B: numpy.ndarray, shape (N_total, N_total)\n",
    "    \"\"\"\n",
    "    # 1) 层顺序与 offset\n",
    "    layers = sorted(layer_nodes.keys())\n",
    "    layer_offset = {}\n",
    "    offset = 0\n",
    "    for layer in layers:\n",
    "        layer_offset[layer] = offset\n",
    "        offset += len(layer_nodes[layer])\n",
    "    N = offset\n",
    "\n",
    "    # 2) 初始化 B 为 0\n",
    "    B = np.zeros((N, N), dtype=float)\n",
    "\n",
    "    # 3) 对角块：每层独立计算 expected_s = (k_s k_s^T) / (2 m_s)\n",
    "    for layer in layers:\n",
    "        A = layer_adj_blocks.get(layer)\n",
    "        if A is None:\n",
    "            # 空层（无节点）\n",
    "            continue\n",
    "        base = layer_offset[layer]\n",
    "        n = A.shape[0]\n",
    "        # 层内度与2m_s\n",
    "        k_s = A.sum(axis=1, keepdims=True)        # (n,1)\n",
    "        two_m_s = float(k_s.sum())                # scalar\n",
    "        if two_m_s > 0:\n",
    "            expected_s = (k_s @ k_s.T) / two_m_s\n",
    "        else:\n",
    "            expected_s = np.zeros_like(A)\n",
    "        B_block = A - gamma * expected_s\n",
    "        # 写进 B 的对角块\n",
    "        B[base:base+n, base:base+n] = B_block\n",
    "\n",
    "    # 4) 添加跨层耦合块（直接加入 B 的 off-diagonal）\n",
    "    #    coupling_blocks[(la,lb)] 形状应为 (len(layer_nodes[la]), len(layer_nodes[lb]))\n",
    "    for (la, lb), C in coupling_blocks.items():\n",
    "        if la not in layer_offset or lb not in layer_offset:\n",
    "            # 忽略未知层（安全检查）\n",
    "            continue\n",
    "        base_a = layer_offset[la]\n",
    "        base_b = layer_offset[lb]\n",
    "        na = C.shape[0]\n",
    "        nb = C.shape[1]\n",
    "        # 在 B 的对应位置直接加上 C（可能是稀疏的）\n",
    "        # 如果 (lb,la) 也在 coupling_blocks，会在其迭代时加对称项两次——\n",
    "        # 因此，期望 coupling_blocks[(lb,la)] == C.T，或只在上三角加入并手动对称填充。\n",
    "        B[base_a:base_a+na, base_b:base_b+nb] += C\n",
    "    # 5) 对称化（保证数值对称）\n",
    "    B = (B + B.T) / 2.0\n",
    "    # 清理数值噪声\n",
    "    B[np.abs(B) < 1e-15] = 0.0\n",
    "    return B\n",
    "\n",
    "\n",
    "\n",
    "def run_genlouvain_on_B(\n",
    "    B: np.ndarray,\n",
    "    matlab_path_to_genlouvain: str,\n",
    "    random_state: int | None = None,\n",
    "    use_iterated: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    把我们在 Python 里构造的 B 发到 MATLAB，调用 genlouvain / iterated_genlouvain，\n",
    "    返回 S (社区标签向量) 和 Q_raw / Q (模块度)。\n",
    "    \"\"\"\n",
    "    import matlab.engine\n",
    "    import matlab\n",
    "\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    # 确保 GenLouvain 在 MATLAB 的 path 里\n",
    "    _ = eng.addpath(eng.genpath(matlab_path_to_genlouvain), nargout=1)\n",
    "\n",
    "    # 转成 matlab.double\n",
    "    # 注意：genlouvain 期望的是稀疏 B，一般很大时要稀疏；这里先给 dense 版。\n",
    "    B_matlab = matlab.double(B.tolist())\n",
    "\n",
    "    if random_state is not None:\n",
    "        eng.eval(f\"rng({int(random_state)});\", nargout=0)\n",
    "\n",
    "    # 试 iterated_genlouvain，回退 genlouvain\n",
    "    try:\n",
    "        if use_iterated:\n",
    "            S, Q_raw = eng.iterated_genlouvain(B_matlab, [], [], 0, nargout=2)\n",
    "        else:\n",
    "            S, Q_raw = eng.genlouvain(B_matlab, nargout=2)\n",
    "    except Exception:\n",
    "        S, Q_raw = eng.genlouvain(B_matlab, nargout=2)\n",
    "\n",
    "    # 取回来 S (长度 = B.shape[0])，Q_raw 是未除以 2m 的版本（在标准流程里 Q = Q_raw / (2m)）\n",
    "    S_py = np.array(S).reshape(-1)\n",
    "    # 为了得到标准化模块度 Q，我们自己也可以算:\n",
    "    # two_m for supra graph = sum(A) (我们可以从外面传进来，如果想严格)\n",
    "    return S_py, float(Q_raw)\n",
    "\n",
    "\n",
    "def multilayer_partition(\n",
    "    csv_path: str,\n",
    "    omega_scale: float,\n",
    "    matlab_path_to_genlouvain: str,\n",
    "    metric: str = \"euclidean\",\n",
    "    node2vec_dim: int = 64,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    端到端:\n",
    "    1. 读边并按 layer 分图\n",
    "    2. 每层跑 node2vec\n",
    "    3. 用 GW 耦合构造跨层耦合 + 超邻接矩阵 A_supra\n",
    "    4. 构造模块度矩阵 B\n",
    "    5. 调用 MATLAB genlouvain\n",
    "    6. 输出 (layer, node, community) 的 DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 读 CSV & 按层建图\n",
    "    df = read_edges(csv_path)\n",
    "    graphs = build_layer_graphs(df)\n",
    "\n",
    "    # 2. 每层 embedding\n",
    "    embeddings = {}\n",
    "    for layer, G in graphs.items():\n",
    "        emb = compute_node2vec_embeddings(\n",
    "            G,\n",
    "            dimensions=node2vec_dim,\n",
    "            walk_length=80,\n",
    "            num_walks=10,\n",
    "            p=1.0,\n",
    "            q=1.0,\n",
    "            window=10,\n",
    "            workers=4,\n",
    "            seed=seed,\n",
    "        )\n",
    "        embeddings[layer] = emb\n",
    "\n",
    "    # 3. 超邻接矩阵\n",
    "    A_supra, global_index, layer_nodes, layer_adj_blocks, coupling_blocks = supra_adjacency_from_pi(\n",
    "        graphs,\n",
    "        embeddings,\n",
    "        metric=metric,\n",
    "        omega_scale=omega_scale,\n",
    "    )\n",
    "\n",
    "    # 4. 模块度矩阵 B\n",
    "    B = build_B_from_blocks(layer_adj_blocks, coupling_blocks, layer_nodes, gamma=1.0)\n",
    "\n",
    "    # 5. 调 MATLAB: genlouvain\n",
    "    S_vec, Q_raw = run_genlouvain_on_B(\n",
    "        B,\n",
    "        matlab_path_to_genlouvain=matlab_path_to_genlouvain,\n",
    "        random_state=seed,\n",
    "        use_iterated=True,\n",
    "    )\n",
    "\n",
    "    # 6. 还原回 (node, layer)\n",
    "    # global_index[i] = (layer, node) 对应 B[i,i]\n",
    "    rows = []\n",
    "    for idx_global, (layer, node) in enumerate(global_index):\n",
    "        rows.append({\n",
    "            \"layer\": layer,\n",
    "            \"node_id\": node,\n",
    "            \"community\": int(S_vec[idx_global]),\n",
    "        })\n",
    "\n",
    "    output_csv = \"output/test_communities.csv\"\n",
    "    part_df = pd.DataFrame(rows, columns=[\"node_id\", \"layer\", \"community\"])\n",
    "    part_df.to_csv(output_csv, index=False)\n",
    "    return part_df, Q_raw, A_supra, B\n",
    "\n",
    "result_df, _, A_supra, B = multilayer_partition(\n",
    "    csv_path=\"sync_data/test.csv\",\n",
    "    omega_scale=10.0,   # 可以加大，比如5.0让跨层更粘\n",
    "    matlab_path_to_genlouvain=\"GenLouvain\",  # 本地GenLouvain的路径\n",
    "    metric=\"euclidean\",\n",
    "    node2vec_dim=64,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55736662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9398389690284362, 0.7141232823369387, 0.8477485906773919, 0.8545606996445992, 0.6931158351648826]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8098774753704496"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from measurement import *\n",
    "\n",
    "compute_layerwise_ami_avg(\"test\",\"sync_data\",output_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9384f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import algorithms\n",
    "from importlib import reload\n",
    "reload(algorithms)\n",
    "from algorithms import *\n",
    "\n",
    "genlouvain_communities(\n",
    "    input_csv=\"sync_data/test.csv\",\n",
    "    output_csv=\"test_communities.csv\",\n",
    "    genlouvain_path=\"GenLouvain\",\n",
    "    omega=0.1,\n",
    "    gamma=1.0,\n",
    "    directed=False,\n",
    "    random_state=None,\n",
    "    use_iterated=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
