{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcea2527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始构建时序图...\n",
      "步骤 1/4: 数据预处理...\n",
      "步骤 2/4: 按 '1h' 的时间窗口对数据进行分组...\n",
      "步骤 3/4: 在每个时间窗口内计算用户轨迹相似度...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理时间窗口: 100%|██████████| 744/744 [3:06:24<00:00, 15.03s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤 4/4: 创建最终的DataFrame...\n",
      "\n",
      "构建完成！结果如下：\n",
      "        user_u  user_v               layer\n",
      "0         1183    5463 2016-08-01 00:00:00\n",
      "1         4666    6667 2016-08-01 00:00:00\n",
      "2           95    3356 2016-08-01 06:00:00\n",
      "3          719    7733 2016-08-01 06:00:00\n",
      "4         1440    4123 2016-08-01 06:00:00\n",
      "...        ...     ...                 ...\n",
      "107191   12929   13470 2016-08-31 23:00:00\n",
      "107192   13416   14714 2016-08-31 23:00:00\n",
      "107193   13459   14714 2016-08-31 23:00:00\n",
      "107194   13470   14042 2016-08-31 23:00:00\n",
      "107195   15764   16452 2016-08-31 23:00:00\n",
      "\n",
      "[107196 rows x 3 columns]\n",
      "\n",
      "结果已保存到文件: temporal_graph_edges.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm  # 引入tqdm来显示进度条\n",
    "\n",
    "# ==============================================================================\n",
    "# 第一部分：辅助函数 (数据处理与相似度计算)\n",
    "# ==============================================================================\n",
    "\n",
    "def haversine_distance(p1, p2):\n",
    "    \"\"\"计算两个经纬度点之间的球面距离（单位：米）。\"\"\"\n",
    "    R = 6371000  # 地球平均半径\n",
    "    lon1, lat1 = p1\n",
    "    lon2, lat2 = p2\n",
    "    lat1_rad, lon1_rad = radians(lat1), radians(lon1)\n",
    "    lat2_rad, lon2_rad = radians(lat2), radians(lon2)\n",
    "    dlon, dlat = lon2_rad - lon1_rad, lat2_rad - lat1_rad\n",
    "    a = sin(dlat / 2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def string_to_trajectory(track_string: str) -> np.ndarray:\n",
    "    \"\"\"将'lon,lat#lon,lat'格式的字符串转换为Numpy轨迹数组。\"\"\"\n",
    "    if not isinstance(track_string, str) or not track_string.strip():\n",
    "        return np.empty((0, 2))\n",
    "    points = []\n",
    "    point_strings = track_string.strip().split('#')\n",
    "    for p_str in point_strings:\n",
    "        coords = p_str.split(',')\n",
    "        if len(coords) == 2:\n",
    "            try:\n",
    "                # 保持 [经度, 纬度] 格式\n",
    "                lon, lat = float(coords[0]), float(coords[1])\n",
    "                points.append([lon, lat])\n",
    "            except (ValueError, TypeError):\n",
    "                # 如果转换失败，跳过这个点\n",
    "                pass\n",
    "    return np.array(points)\n",
    "\n",
    "def lcss_similarity(traj_a: np.ndarray, traj_b: np.ndarray, epsilon: float) -> float:\n",
    "    \"\"\"使用动态规划计算两条轨迹的LCSS相似度 (0-1之间)。\"\"\"\n",
    "    m, n = len(traj_a), len(traj_b)\n",
    "    if m == 0 or n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    lcss_matrix = np.zeros((m + 1, n + 1))\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if haversine_distance(traj_a[i-1], traj_b[j-1]) <= epsilon:\n",
    "                lcss_matrix[i, j] = 1 + lcss_matrix[i-1, j-1]\n",
    "            else:\n",
    "                lcss_matrix[i, j] = max(lcss_matrix[i-1, j], lcss_matrix[i, j-1])\n",
    "    \n",
    "    lcss_length = lcss_matrix[m, n]\n",
    "    return lcss_length / ((m+n)/2)\n",
    "\n",
    "# ==============================================================================\n",
    "# 第二部分：构建时序图的主函数\n",
    "# ==============================================================================\n",
    "\n",
    "def build_temporal_graph(df: pd.DataFrame, epsilon: float, sigma: float, window_size: str = '1h') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从轨迹数据构建时序图。\n",
    "\n",
    "    参数:\n",
    "        df (pd.DataFrame): 包含轨迹数据的DataFrame。\n",
    "        epsilon (float): LCSS的距离阈值（米），用于判断点是否匹配。\n",
    "        sigma (float): 轨迹相似度阈值（0-1），用于判断是否连接用户。\n",
    "        window_size (str): Pandas时间窗口大小（例如 '1H', '30min', '1D'）。\n",
    "\n",
    "    返回:\n",
    "        pd.DataFrame: 包含图连接信息的DataFrame，列为 [user_u, user_v, layer]。\n",
    "    \"\"\"\n",
    "    # --- 1. 数据预处理 ---\n",
    "    print(\"步骤 1/4: 数据预处理...\")\n",
    "    # 复制数据，避免修改原始DataFrame\n",
    "    processed_df = df.copy()\n",
    "    # 转换时间列为datetime对象\n",
    "    processed_df['start_time'] = pd.to_datetime(processed_df['start_time'])\n",
    "    # 将track字符串解析为Numpy数组，方便后续计算\n",
    "    processed_df['trajectory'] = processed_df['track'].apply(string_to_trajectory)\n",
    "    # 设置时间为索引，方便分片\n",
    "    processed_df.set_index('start_time', inplace=True)\n",
    "    \n",
    "    # --- 2. 按时间窗口分组 ---\n",
    "    print(f\"步骤 2/4: 按 '{window_size}' 的时间窗口对数据进行分组...\")\n",
    "    grouped_by_window = processed_df.groupby(pd.Grouper(freq=window_size))\n",
    "    \n",
    "    edge_list = []\n",
    "    \n",
    "    print(\"步骤 3/4: 在每个时间窗口内计算用户轨迹相似度...\")\n",
    "    # 使用tqdm来可视化处理进度\n",
    "    for window_start_time, group_df in tqdm(grouped_by_window, desc=\"处理时间窗口\"):\n",
    "        if len(group_df) < 2:\n",
    "            continue # 如果窗口内订单少于2，无法形成连接，跳过\n",
    "        \n",
    "        # 为了处理一个用户在窗口内有多次出行的情况，我们按用户ID分组\n",
    "        # 并将同一用户的所有轨迹合并为一个长轨迹\n",
    "        user_trajectories = {}\n",
    "        for userid, user_trips in group_df.groupby('userid'):\n",
    "            # 过滤掉空轨迹并合并\n",
    "            valid_trajectories = [traj for traj in user_trips['trajectory'] if traj.size > 0]\n",
    "            if valid_trajectories:\n",
    "                user_trajectories[userid] = np.vstack(valid_trajectories)\n",
    "\n",
    "        # 获取当前窗口内有有效轨迹的用户列表\n",
    "        users_in_window = list(user_trajectories.keys())\n",
    "        \n",
    "        # 如果活跃用户少于2，也跳过\n",
    "        if len(users_in_window) < 2:\n",
    "            continue\n",
    "\n",
    "        # --- 3. 计算窗口内用户对的相似度 ---\n",
    "        # 使用itertools.combinations高效生成所有用户对\n",
    "        for user_u, user_v in combinations(users_in_window, 2):\n",
    "            traj_u = user_trajectories[user_u]\n",
    "            traj_v = user_trajectories[user_v]\n",
    "            \n",
    "            similarity = lcss_similarity(traj_u, traj_v, epsilon=epsilon)\n",
    "            \n",
    "            # --- 4. 如果相似度达到阈值，添加边 ---\n",
    "            if similarity >= sigma:\n",
    "                # 确保user_u始终小于user_v，避免重复边 (u,v) 和 (v,u)\n",
    "                u, v = sorted((user_u, user_v))\n",
    "                edge_list.append({\n",
    "                    'user_u': u,\n",
    "                    'user_v': v,\n",
    "                    'layer': window_start_time\n",
    "                })\n",
    "\n",
    "    print(\"步骤 4/4: 创建最终的DataFrame...\")\n",
    "    if not edge_list:\n",
    "        print(\"警告：没有找到任何符合条件的相似用户对。返回一个空的DataFrame。\")\n",
    "        return pd.DataFrame(columns=['user_u', 'user_v', 'layer'])\n",
    "        \n",
    "    result_df = pd.DataFrame(edge_list)\n",
    "    # 去除在同一个时间层内可能出现的重复边\n",
    "    result_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# ==============================================================================\n",
    "# 第三部分：示例用法\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv(\"transport_data/mobike_shanghai_sample_updated.csv\")\n",
    "    # --- 设置参数 ---\n",
    "    # LCSS距离阈值：如果两个GPS点相距200米以内，则认为它们匹配\n",
    "    EPSILON_METERS = 1000 \n",
    "    # 相似度阈值：如果两条轨迹的LCSS相似度得分高于等于0.8，则连接\n",
    "    SIGMA_THRESHOLD = 0.5\n",
    "    # 时间窗口\n",
    "    WINDOW = '1h'\n",
    "\n",
    "    # --- 运行主函数 ---\n",
    "    print(\"\\n开始构建时序图...\")\n",
    "    temporal_graph_df = build_temporal_graph(\n",
    "        df=data,\n",
    "        epsilon=EPSILON_METERS,\n",
    "        sigma=SIGMA_THRESHOLD,\n",
    "        window_size=WINDOW\n",
    "    )\n",
    "\n",
    "    # --- 显示并保存结果 ---\n",
    "    print(\"\\n构建完成！结果如下：\")\n",
    "    print(temporal_graph_df)\n",
    "\n",
    "    if not temporal_graph_df.empty:\n",
    "        output_filename = 'temporal_graph_edges.csv'\n",
    "        temporal_graph_df.to_csv(output_filename, index=False)\n",
    "        print(f\"\\n结果已保存到文件: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
